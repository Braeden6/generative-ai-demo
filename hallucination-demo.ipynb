{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "from typing import Optional, Union, List, Tuple\n",
    "from pypdf import PdfReader\n",
    "import textwrap\n",
    "import requests\n",
    "import io\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.schema import SystemMessage \n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.schema import Document\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF already downloaded\n"
     ]
    }
   ],
   "source": [
    "from download_pdf import download_pdf\n",
    "file_name = os.getcwd() + \"/pdfs/\" + os.getenv(\"PDF_FILE_NAME\")\n",
    "download_pdf(os.getenv(\"PDF_URL\"), file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_splitter_recursive(full_path: str, chunk_size:int = 1000, chunk_overlap: int = 100) -> List[Document]:\n",
    "    '''\n",
    "    Split a PDF file into a list of documents using a recursive character splitter\n",
    "    '''\n",
    "    loader = PyPDFLoader(full_path)\n",
    "    doc = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs = text_splitter.split_documents(doc)\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(docs: List[Document], embeddings: Embeddings, save_location: str) -> FAISS:\n",
    "    '''\n",
    "    Compute embeddings for a PDF file and save them to file\n",
    "    '''\n",
    "    # Compute embeddings\n",
    "    docsearch = FAISS.from_documents(docs, embeddings)\n",
    "    # Save embeddings to file\n",
    "    with open(save_location, 'wb') as f:\n",
    "        pickle.dump(docsearch, f)\n",
    "    print(\"Embeddings computed and saved to file\")\n",
    "    return docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def answer_question(question: str, chat: ChatOpenAI, \n",
    "                          prompt_template: PromptTemplate,\n",
    "                          relevant_information: Optional[str] = None, \n",
    "                          docsearch: Optional[FAISS] = None, \n",
    "                          similar_doc_count: int = 10,\n",
    "                          verbose: bool = False) -> Tuple[str, List[Document]]:\n",
    "    '''\n",
    "    Answer a question using a chatbot and relevant information\n",
    "    '''\n",
    "    similar_docs = []\n",
    "    # Notifying user that given relevant information will be used\n",
    "    if relevant_information is not None:\n",
    "        if verbose:\n",
    "            print(\"Using provided relevant information instead of embeddings\")\n",
    "\n",
    "    # Use embeddings to find relevant information if relevant information is not provided\n",
    "    elif docsearch is not None:\n",
    "        if verbose:\n",
    "            print(\"Using provided embeddings to find relevant information\")\n",
    "        similar_docs = await docsearch.asimilarity_search(question, k=similar_doc_count)\n",
    "        relevant_information = \"\\n\".join([doc.page_content for doc in similar_docs])\n",
    "\n",
    "    # Relevant information is not provided, then raise error\n",
    "    if relevant_information is None:\n",
    "        raise ValueError(\"No relevant information generated. Either provide relevant information or docsearch (FAISS object)\")\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Relevant information length: {len(relevant_information)}\")\n",
    "\n",
    "    formatted_prompt = prompt_template.format(question=question, relevant_information=relevant_information)\n",
    "\n",
    "    answer = chat([SystemMessage(content=formatted_prompt)])\n",
    "    return answer.content, similar_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings file already exists for recursive splitter\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"gpt-3.5-turbo\"\n",
    "# MODEL = \"gpt-4\"\n",
    "chat = ChatOpenAI(temperature=0, model_name=MODEL) # type: ignore\n",
    "embeddings = OpenAIEmbeddings() # type: ignore\n",
    "pdf_path_page = os.getcwd() + \"/pdfs/\" + os.getenv(\"PDF_FILE_NAME\") # type: ignore\n",
    "\n",
    "embeddings_recursive = os.getcwd() + \"/embeddings/\" + os.getenv(\"EMBEDDINGS_BY_CHUNK_FILE_NAME\") # type: ignore\n",
    "if os.path.exists(embeddings_recursive):\n",
    "    print(\"Embeddings file already exists for recursive splitter\")\n",
    "    # read embeddings object from file\n",
    "    with open(embeddings_recursive, 'rb') as f:\n",
    "        docsearch_recursive = pickle.load(f)\n",
    "else:\n",
    "    print(\"Embeddings file does not exist for recursive splitter\")\n",
    "    # compute embeddings\n",
    "    docs = doc_splitter_recursive(pdf_path_page, chunk_size=1000, chunk_overlap=100)\n",
    "    docsearch_recursive = compute_embeddings(docs, embeddings, embeddings_recursive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_answer_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the question below. Some information is provided. \n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Relevant Information: {relevant_information}\n",
    "\"\"\")\n",
    "\n",
    "restrictive_answer_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You will answer a question based of the given information below. If the relevant information\n",
    "does not answer the question, then just say \"No sure\".\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Relevant Information: {relevant_information} \n",
    "\"\"\")\n",
    "\n",
    "\n",
    "mostly_restrictive_answer_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You will answer a question based of the given information below. Try your best to answer the question\n",
    "using the relevant information. But do not make anything up that is not supported, just say \"No sure\"\n",
    "                                                                                                                \n",
    "Question: {question}\n",
    "\n",
    "Relevant Information: {relevant_information} \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple example\n",
    "\n",
    "In this example the the simple and restrictive prompts should result in similar answers, as the provided information is very specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The name of the main character in Harry Potter is\n",
      "Harry Potter.\n",
      "\n",
      "\n",
      "Answer: The name of the main character in Harry Potter is\n",
      "Harry Potter.\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"What is the name of the main character in Harry Potter?\"\n",
    "relevant_text = \"Harry Potter is the main character of the Harry Potter series.\"\n",
    "answer, _ = await answer_question(QUESTION, chat, simple_answer_prompt, relevant_information=relevant_text)\n",
    "print(f\"Answer: {textwrap.fill(answer, 50)}\")\n",
    "answer, _ = await answer_question(QUESTION, chat, restrictive_answer_prompt, relevant_information=relevant_text)\n",
    "print(f\"\\n\\nAnswer: {textwrap.fill(answer, 50)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restrictive vs Simple Prompt\n",
    "\n",
    "Here we should see that the restrictive prompt will not be able to answer the question as no information is provided about the specific question. Whereas, the simple prompt will give an answer, but founded from the models training data and not from the provided information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The name of the main character in Harry Potter is\n",
      "Harry Potter.\n",
      "\n",
      "\n",
      "Answer: No sure.\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"What is the name of the main character in Harry Potter?\"\n",
    "irrelevant_text = \"This is a test.\"\n",
    "answer, _ = await answer_question(QUESTION, chat, simple_answer_prompt, relevant_information=irrelevant_text)\n",
    "print(f\"Answer: {textwrap.fill(answer, 50)}\")\n",
    "answer, _ = await answer_question(QUESTION, chat, restrictive_answer_prompt, relevant_information=irrelevant_text)\n",
    "print(f\"\\n\\nAnswer: {textwrap.fill(answer, 50)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example using Restrictive Prompt and Irrelevant or Relevant Information\n",
    "\n",
    "**Question**: Were the house points used much?\n",
    "\n",
    "This question refers to the difference between the books and movies. The movies does not use the house point system that much, but in the books it is different.. More details can be found [here](https://harrypotter.fandom.com/wiki/List_of_differences_between_the_Harry_Potter_books_and_films#1._House_points).\n",
    "\n",
    "**Non-Restrictive Prompt with Irrelevant Information:** \n",
    "The answer, in this case, may not be reliable as it lacks evidence or related context.\n",
    "\n",
    "**Restrictive Prompt with Irrelevant Information:** \n",
    "The system should not attempt to answer the question due to the absence of pertinent data.\n",
    "\n",
    "**Restrictive Prompt with Relevant Information:** \n",
    "The system is expected to answer the question accurately due to the provision of context-specific data from a relevant source.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non restrictive prompt with irrelevant information\n",
      "Answer: No, the information provided does not mention\n",
      "anything about house points being used or not.\n",
      "\n",
      "\n",
      "Restrictive prompt with irrelevant information\n",
      "Answer: No sure.\n",
      "\n",
      "\n",
      "Non restrictive prompt with relevant information\n",
      "Using provided embeddings to find relevant information\n",
      "Relevant information length: 9721\n",
      "Answer: Yes, the house points were used quite a bit.\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"Were the house points used much?\"\n",
    "irrelevant_text = \"This is a test.\"\n",
    "print(\"Non restrictive prompt with irrelevant information\")\n",
    "answer, _ = await answer_question(QUESTION, chat, simple_answer_prompt, relevant_information=irrelevant_text)\n",
    "print(f\"Answer: {textwrap.fill(answer, 50)}\")\n",
    "print(\"\\n\\nRestrictive prompt with irrelevant information\")\n",
    "answer, _ = await answer_question(QUESTION, chat, restrictive_answer_prompt, relevant_information=irrelevant_text)\n",
    "print(f\"Answer: {textwrap.fill(answer, 50)}\")\n",
    "print(\"\\n\\nNon restrictive prompt with relevant information\")\n",
    "answer, _ = await answer_question(QUESTION, chat, restrictive_answer_prompt, docsearch=docsearch_recursive, similar_doc_count=12, verbose=True)\n",
    "print(f\"Answer: {textwrap.fill(answer, 50)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All vs Some\n",
    "\n",
    "Here is a cool example of the difference of how you word the question. The first question asks for all whereas, the second question asks for some. The answers are very different. The model should be able to pick up on the fact that it can not reliably give all, but with some relevant information it can definitely give some."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the given information, the horcruxes from\n",
      "Harry Potter are:  1. Tom Riddle's diary 2.\n",
      "Marvolo Gaunt's ring 3. Salazar Slytherin's locket\n",
      "4. Helga Hufflepuff's cup 5. Rowena Ravenclaw's\n",
      "diadem 6. Harry Potter himself (unintentional\n",
      "horcrux) 7. Nagini, Voldemort's snake  It is\n",
      "mentioned that Voldemort had secured objects from\n",
      "Hufflepuff and Slytherin, and he set out to track\n",
      "down objects owned by Gryffindor or Ravenclaw. The\n",
      "only known relic of Gryffindor mentioned is the\n",
      "ruby-encrusted sword, which is not a horcrux. It\n",
      "is also mentioned that Voldemort may have found\n",
      "three horcruxes, but it is not specified which\n",
      "ones. However, it is later revealed that Nagini is\n",
      "the sixth horcrux.\n",
      "\n",
      "\n",
      "Answer: Based on the given information, some of the\n",
      "horcruxes mentioned are:  - The diary, which was\n",
      "proof that Voldemort was the Heir of Slytherin -\n",
      "The locket, which was one of Voldemort's horcruxes\n",
      "- Objects from Hufflepuff and Slytherin, which\n",
      "Voldemort may have used as horcruxes - Objects\n",
      "from Gryffindor and Ravenclaw, which Voldemort may\n",
      "have also used as horcruxes - Nagini, Voldemort's\n",
      "snake, which Dumbledore suspects may be a horcrux\n",
      "- The basilisk fangs, which Ron and Hermione used\n",
      "to destroy horcruxes  However, it is important to\n",
      "note that the specific details and locations of\n",
      "all the horcruxes are not provided in the given\n",
      "information.\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"Can you tell me all the horcruxes from Harry Potter?\"\n",
    "answer, _ = await answer_question(QUESTION, chat, restrictive_answer_prompt, docsearch=docsearch_recursive, similar_doc_count=10)\n",
    "print(f\"Answer: {textwrap.fill(answer, 50)}\")\n",
    "QUESTION = \"Can you tell about some of the horcruxes?\"\n",
    "answer, _ = await answer_question(QUESTION, chat, restrictive_answer_prompt, docsearch=docsearch_recursive, similar_doc_count=10)\n",
    "print(f\"\\n\\nAnswer: {textwrap.fill(answer, 50)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Nearly Headless Nick's full name is Sir Nicholas\n",
      "de Mimsy-Porpington.\n",
      "Answer: Nicholas Flamel was 665 years old when he decided\n",
      "to destroy the Sorcerer's Stone.\n",
      "Answer: Monkshood and wolfsbane are also known as aconite.\n",
      "Answer: No sure.\n",
      "Answer: The ingredients contained in Polyjuice Potion are\n",
      "lacewing flies, leeches, fluxweed, knotgrass, and\n",
      "three unknown ingredients.\n",
      "Answer: There is no information given about the number of\n",
      "possible Quidditch fouls.\n",
      "Answer: The final tally was 472 points for Gryffindor and\n",
      "472 points for Slytherin.\n",
      "Answer: No sure.\n",
      "Answer: Vernon Dursley works at a company called\n",
      "Grunnings. The company produces drills.\n",
      "Answer: No sure.\n",
      "Answer: The statue next to the special lavatory entrance\n",
      "is Boris the Bewildered.\n",
      "Answer: The max speed for a Firebolt broomstick is not\n",
      "mentioned in the given information.\n",
      "Answer: No sure.\n",
      "Answer: No sure.\n",
      "Answer: The first goal was scored by Moran.\n",
      "Answer: No sure.\n",
      "Answer: The five-digit code you must dial to get into the\n",
      "Ministry of Magic is 62442.\n",
      "Answer: The name of the Apparition instructor who comes to\n",
      "Hogwarts in Harry's sixth year is Wilkie Twycross.\n",
      "Answer: The name of Hepzibah Smith's house-elf is Hokey.\n",
      "Answer: No sure.\n",
      "Answer: No sure.\n"
     ]
    }
   ],
   "source": [
    "# https://www.insider.com/harry-potter-trivia-2016-11#harry-ron-and-hermione-help-save-the-sorcerers-stone-from-being-stolen-how-old-was-its-co-creator-nicholas-flamel-when-he-decided-to-destroy-it-2\n",
    "QUESTIONS = [\n",
    "    \"Many know that Gryffindor's ghost is Nearly Headless Nick. But what is his full name?\",\n",
    "    #  Sir Nicholas de Mimsy-Porpington.\n",
    "    \"Harry, Ron, and Hermione help save the Sorcerer's Stone from being stolen. How old was its co-creator, Nicholas Flamel, when he decided to destroy it?\",\n",
    "    #  665\n",
    "    \"Monkshood and wolfsbane are the same plant, also known as what?\",\n",
    "    #  Aconite\n",
    "    \"How many staircases does Hogwarts have?\",\n",
    "    #  142\n",
    "    \"Name every ingredient contained in Polyjuice Potion. (Hint: There are seven.)\",\n",
    "    # Lacewing flies, leeches, powdered Bicorn horn, knotgrass, fluxweed, shredded Boomslang skin, and a bit of the person you want to turn into.\n",
    "    \"How many possible Quidditch fouls are there?\",\n",
    "    #  700\n",
    "    \"In The Sorcerer\\’s Stone, Harry and his friends are awarded last-minute House Points, putting Gryffindor ahead of Slytherin by just 10 points. What was the final tally?\",\n",
    "    #  482 to 472\n",
    "    \"Dumbledore has a scar above his left knee that is a perfect map of what?\",\n",
    "    #  The London Underground\n",
    "    \"This one is a two-parter. Where does Vernon Dursley work, and what does the company produce?\",\n",
    "    # Grunnings, a drill manufacturer.\n",
    "    \"For Harry's 17th birthday, what color did Hermione turn the leaves of the Weasley’s crabapple tree?\",\n",
    "    #  Gold\n",
    "    \"Cedric Diggory let Harry use the prefect's bathroom in The Goblet of Fire. What man's statue is next to the special lavatory entrance?\",\n",
    "    #  Boris the Bewildered\n",
    "    \"What is the max speed for a Firebolt broomstick?\",\n",
    "    #  150 mph\n",
    "    \"Harry first took the Knight Bus in The Prisoner of Azkaban. How much does a ticket cost if it includes hot chocolate?\",\n",
    "    #  14 Sickles\n",
    "    \"In the Hall of Prophecy there are rows and rows of glowing orbs. Which row contains the prophecy about Harry and Voldemort?\",\n",
    "    #  97\n",
    "    \"In the Quidditch World Cup, Ireland's team had three main chasers: Mullet, Troy, and Moran. Which one scored the first goal?\",\n",
    "    #  Troy\n",
    "    \"On the wall across from the Room of Requirement, there is a tapestry showing a wizard trying to teach trolls ballet. What's his name?\",\n",
    "    #  Barnabas the Barmy\n",
    "    \"The visitor’s entrance to the Ministry of Magic is an abandoned red telephone booth in London. What is the five-digit code you must dial to get in?\",\n",
    "    #  62442\n",
    "    \"What is the name of the Apparition instructor who comes to Hogwarts in Harry's sixth year?\",\n",
    "    #  Wilkie Twycross\n",
    "    \"Voldemort stole Helga Hufflepuff's cup from an old woman named Hepzibah Smith. What was the name of her house-elf?\",\n",
    "    #  Hokey\n",
    "    \"Ginny Weasley bought a pet Pygmy Puff from her older brothers' joke shop. What did she name it?\",\n",
    "    #  Arnold\n",
    "    \"What is Fred Weasley's chosen code name on Potterwatch, the secretive radio program set up by the Order of the Phoenix?\",\n",
    "    #  Rapier\n",
    "]\n",
    "\n",
    "for question in QUESTIONS:\n",
    "    answer, _ = await answer_question(question, chat, restrictive_answer_prompt, docsearch=docsearch_recursive, similar_doc_count=5)\n",
    "    print(f\"Answer: {textwrap.fill(answer, 50)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of results\n",
    "9 correct, 2 incorrect, 10 unanswered \n",
    "#### Notes\n",
    "However, if you change the prompt, amount of relevant information, and possible temperature, you can get the answers to almost all questions. This means you could possible combine results using bootstrapping or ensemble learning. The ideas of combining results from multiple models increasing the accuracy and reducing the bias. \n",
    "[ensemble learning](https://machinelearningmastery.com/tour-of-ensemble-learning-algorithms/)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the given information, it is unclear\n",
      "whether Sirius Black was a good person or not. The\n",
      "Wizarding world believed him to be a dangerous\n",
      "murderer and a supporter of Voldemort. However,\n",
      "there is evidence suggesting that he may not have\n",
      "committed the crimes he was accused of. According\n",
      "to Doris Purkiss, Sirius Black may not have even\n",
      "been present at the killings and the man people\n",
      "believe to be Sirius Black is actually Stubby\n",
      "Boardman, a retired singer. Additionally,\n",
      "Slughorn, a former teacher, speaks positively of\n",
      "Sirius and mentions that he was a talented boy.\n",
      "Ultimately, it is up to interpretation whether\n",
      "Sirius Black was a good person or not.\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"Was Sirius Black a good person?\"\n",
    "\n",
    "answer, _ = await answer_question(QUESTION, chat, restrictive_answer_prompt, docsearch=docsearch_recursive, similar_doc_count=5)\n",
    "print(f\"Answer: {textwrap.fill(answer, 50)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance of Metadata in Document Processing with Generative AI\n",
    "\n",
    "In the era of generative AI models, the significance of metadata in document processing has been further amplified. Metadata encapsulates essential information about data, making it an invaluable asset for maintaining the integrity and transparency of AI operations. \n",
    "\n",
    "## Traceability and Verification\n",
    "\n",
    "Metadata serves as a roadmap, providing crucial details about the source of the information. For generative AI, which is capable of producing large volumes of text, it is vital to keep track of the original sources. The reasons are multifold:\n",
    "\n",
    "1. **Avoiding Misinformation**: Metadata can help ensure the AI model doesn't \"hallucinate,\" or generate information that isn't supported by the input data. By keeping track of the source information, we can verify the generated output against the original context.\n",
    "\n",
    "2. **Double-checking Facts**: For sensitive applications such as scientific research or engineering projects, it's crucial to confirm the accuracy of generated information. Metadata allows users to trace back to the original sources, facilitating the verification process.\n",
    "\n",
    "3. **Citation and Accountability**: Accurate metadata allows for proper citation of the information's source. This not only fulfills academic and professional standards but also promotes accountability and fairness in knowledge sharing.\n",
    "\n",
    "## Metadata: The Silent Workhorse\n",
    "\n",
    "The versatility of metadata allows it to store a wide range of information, from links and page numbers to author names and text sections. However, its significance transcends these particulars. \n",
    "\n",
    "In the vast, interconnected data ecosystems where generative AI operates, metadata functions as the connective tissue, bridging the gap between massive data volumes and precise, reliable outcomes. \n",
    "\n",
    "In summary, the use of metadata is instrumental in preserving the reliability, traceability, and accountability of generative AI systems. By maintaining a clear line of sight to source information, metadata acts as a robust tool for users to verify facts and ensure the integrity of their work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings file already exists for page splitter\n"
     ]
    }
   ],
   "source": [
    "def doc_splitter_by_page(file: io.BytesIO, metadata: dict) -> List[Document]:\n",
    "    '''\n",
    "    Split a PDF file into a list of documents by page\n",
    "    '''\n",
    "    reader = PdfReader(file)\n",
    "    return [\n",
    "        Document(\n",
    "            page_content=page.extract_text(),\n",
    "            metadata={\n",
    "                        **metadata,\n",
    "                        \"page\": page_number, \n",
    "                    },\n",
    "        )\n",
    "        for page_number, page in enumerate(reader.pages)\n",
    "    ]\n",
    "\n",
    "\n",
    "embeddings_path_page = os.getcwd() + \"/embeddings/\" + os.getenv(\"EMBEDDINGS_BY_PAGE_FILE_NAME\") # type: ignore\n",
    "if os.path.exists(embeddings_path_page):\n",
    "    print(\"Embeddings file already exists for page splitter\")\n",
    "    # read embeddings object from file\n",
    "    with open(embeddings_path_page, 'rb') as f:\n",
    "        docsearch_page = pickle.load(f)\n",
    "else:\n",
    "    print(\"Embeddings file does not exist for page splitter\")\n",
    "    # load file into BytesIO object\n",
    "    with open(pdf_path_page, 'rb') as f:\n",
    "        file = io.BytesIO(f.read())\n",
    "    # compute embeddings\n",
    "    docs = doc_splitter_by_page(file, { \"source\": os.getenv(\"PDF_URL\")})\n",
    "    docsearch_page = compute_embeddings(docs, embeddings, embeddings_path_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The flying car skimmed the sea of fluffy clouds,\n",
      "flew past swirls and turrets of snowy clouds, and\n",
      "landed next to a tumbledown garage in Ron's yard.\n",
      "The car could also become invisible with the press\n",
      "of a button. However, the car had some issues,\n",
      "such as a faulty invisibility booster and a\n",
      "malfunctioning engine. It also nearly crashed into\n",
      "a solid castle wall and plummeted towards the\n",
      "ground before stopping abruptly at the edge of the\n",
      "forest.\n",
      "\n",
      "Answer: Based on the given information, the things that\n",
      "happen to the flying car are:  1. The car flies\n",
      "over a sea of fluffy clouds with a bright blue sky\n",
      "and a blinding white sun. 2. Ron and Harry laugh\n",
      "uncontrollably in the car. 3. They land next to\n",
      "Ron's house, which is a crooked stone pigpen with\n",
      "added rooms and several chimneys. 4. Ron presses a\n",
      "button on the dashboard and the car becomes\n",
      "invisible, with Harry and Ron floating as\n",
      "disembodied eyeballs above the ground. 5. The car\n",
      "reappears and they continue flying over London,\n",
      "seeing the city below them. 6. The car becomes\n",
      "faulty and they pummel the Invisibility Booster,\n",
      "causing the car to vanish. 7. They reappear in a\n",
      "dingy street full of parked cars. 8. The car rises\n",
      "again and they see London below them before\n",
      "reappearing. 9. The car is seen by Muggles,\n",
      "causing a headline in the Evening Prophet. 10. The\n",
      "car stops suddenly at the edge of the forest and\n",
      "they get out. 11. The car reverses back into the\n",
      "forest and disappears from view. 12. Harry and Ron\n",
      "follow the spiders after leaving the car. 13. The\n",
      "car is used to escape from Privet Drive, with\n",
      "Harry yelling at his relatives from the car\n",
      "window. 14. Hedwig is let out of the car to fly\n",
      "alongside them. 15. The car is parked and they\n",
      "plan to sneak back into the house without anyone\n",
      "knowing they flew the car.\n",
      "\n",
      "Sources:\n",
      "Source: https://ztcprep.com/library/story/Harry_Potter/Harry_Potter_(www.ztcprep.com).pdf\n",
      "Page: 635\n",
      "Source: https://ztcprep.com/library/story/Harry_Potter/Harry_Potter_(www.ztcprep.com).pdf\n",
      "Page: 569\n",
      "Source: https://ztcprep.com/library/story/Harry_Potter/Harry_Potter_(www.ztcprep.com).pdf\n",
      "Page: 633\n",
      "Source: https://ztcprep.com/library/story/Harry_Potter/Harry_Potter_(www.ztcprep.com).pdf\n",
      "Page: 4485\n",
      "Source: https://ztcprep.com/library/story/Harry_Potter/Harry_Potter_(www.ztcprep.com).pdf\n",
      "Page: 636\n",
      "Source: https://ztcprep.com/library/story/Harry_Potter/Harry_Potter_(www.ztcprep.com).pdf\n",
      "Page: 648\n",
      "Source: https://ztcprep.com/library/story/Harry_Potter/Harry_Potter_(www.ztcprep.com).pdf\n",
      "Page: 2229\n",
      "Source: https://ztcprep.com/library/story/Harry_Potter/Harry_Potter_(www.ztcprep.com).pdf\n",
      "Page: 982\n",
      "Source: https://ztcprep.com/library/story/Harry_Potter/Harry_Potter_(www.ztcprep.com).pdf\n",
      "Page: 562\n",
      "Source: https://ztcprep.com/library/story/Harry_Potter/Harry_Potter_(www.ztcprep.com).pdf\n",
      "Page: 570\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"can you give me the things that happen to the flying car\"\n",
    "answer, _ = await answer_question(QUESTION, chat, restrictive_answer_prompt, docsearch=docsearch_recursive, similar_doc_count=10)\n",
    "print(f\"Answer: {textwrap.fill(answer, 50)}\")\n",
    "answer, similar_docs = await answer_question(QUESTION, chat, restrictive_answer_prompt, docsearch=docsearch_page, similar_doc_count=10)\n",
    "print(f\"\\nAnswer: {textwrap.fill(answer, 50)}\")\n",
    "\n",
    "print(\"\\nSources:\")\n",
    "for doc in similar_docs:\n",
    "    print(f\"Source: {doc.metadata['source']}\")\n",
    "    print(f\"Page: {doc.metadata['page']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
