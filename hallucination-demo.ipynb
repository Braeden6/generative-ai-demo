{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "from typing import Optional, Union, List, Tuple\n",
    "from pypdf import PdfReader\n",
    "import textwrap\n",
    "import requests\n",
    "import io\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.schema import SystemMessage \n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.schema import Document\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download_pdf import download_pdf\n",
    "file_name = os.getcwd() + \"/pdfs/\" + os.getenv(\"PDF_FILE_NAME\")\n",
    "download_pdf(os.getenv(\"PDF_URL\"), file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_splitter_recursive(full_path: str, chunk_size:int = 1000, chunk_overlap: int = 100) -> List[Document]:\n",
    "    '''\n",
    "    Split a PDF file into a list of documents using a recursive character splitter\n",
    "    '''\n",
    "    loader = PyPDFLoader(full_path)\n",
    "    doc = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs = text_splitter.split_documents(doc)\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(docs: List[Document], embeddings: Embeddings, save_location: str) -> FAISS:\n",
    "    '''\n",
    "    Compute embeddings for a PDF file and save them to file\n",
    "    '''\n",
    "    # Compute embeddings\n",
    "    docsearch = FAISS.from_documents(docs, embeddings)\n",
    "    # Save embeddings to file\n",
    "    with open(save_location, 'wb') as f:\n",
    "        pickle.dump(docsearch, f)\n",
    "    print(\"Embeddings computed and saved to file\")\n",
    "    return docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def answer_question(question: str, chat: ChatOpenAI, \n",
    "                          prompt_template: PromptTemplate,\n",
    "                          relevant_information: Optional[str] = None, \n",
    "                          docsearch: Optional[FAISS] = None, \n",
    "                          similar_doc_count: int = 10,\n",
    "                          verbose: bool = False) -> Tuple[str, List[Document]]:\n",
    "    '''\n",
    "    Answer a question using a chatbot and relevant information\n",
    "    '''\n",
    "    similar_docs = []\n",
    "    # Notifying user that given relevant information will be used\n",
    "    if relevant_information is not None:\n",
    "        if verbose:\n",
    "            print(\"Using provided relevant information instead of embeddings\")\n",
    "\n",
    "    # Use embeddings to find relevant information if relevant information is not provided\n",
    "    elif docsearch is not None:\n",
    "        if verbose:\n",
    "            print(\"Using provided embeddings to find relevant information\")\n",
    "        similar_docs = await docsearch.asimilarity_search(question, k=similar_doc_count)\n",
    "        relevant_information = \"\\n\".join([doc.page_content for doc in similar_docs])\n",
    "\n",
    "    # Relevant information is not provided, then raise error\n",
    "    if relevant_information is None:\n",
    "        raise ValueError(\"No relevant information generated. Either provide relevant information or docsearch (FAISS object)\")\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Relevant information length: {len(relevant_information)}\")\n",
    "\n",
    "    formatted_prompt = prompt_template.format(question=question, relevant_information=relevant_information)\n",
    "\n",
    "    answer = chat([SystemMessage(content=formatted_prompt)])\n",
    "    return answer.content, similar_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-3.5-turbo\"\n",
    "# MODEL = \"gpt-4\"\n",
    "chat = ChatOpenAI(temperature=0, model_name=MODEL) # type: ignore\n",
    "embeddings = OpenAIEmbeddings() # type: ignore\n",
    "pdf_path_page = os.getcwd() + \"/pdfs/\" + os.getenv(\"PDF_FILE_NAME\") # type: ignore\n",
    "\n",
    "embeddings_recursive = os.getcwd() + \"/embeddings/\" + os.getenv(\"EMBEDDINGS_BY_CHUNK_FILE_NAME\") # type: ignore\n",
    "if os.path.exists(embeddings_recursive):\n",
    "    print(\"Embeddings file already exists for recursive splitter\")\n",
    "    # read embeddings object from file\n",
    "    with open(embeddings_recursive, 'rb') as f:\n",
    "        docsearch_recursive = pickle.load(f)\n",
    "else:\n",
    "    print(\"Embeddings file does not exist for recursive splitter\")\n",
    "    # compute embeddings\n",
    "    docs = doc_splitter_recursive(pdf_path_page, chunk_size=1000, chunk_overlap=100)\n",
    "    docsearch_recursive = compute_embeddings(docs, embeddings, embeddings_recursive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_answer_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the question below. Some information is provided. \n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Relevant Information: {relevant_information}\n",
    "\"\"\")\n",
    "\n",
    "restrictive_answer_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You will answer a question based of the given information below. If the relevant information\n",
    "does not answer the question, then just say \"No sure\".\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Relevant Information: {relevant_information} \n",
    "\"\"\")\n",
    "\n",
    "\n",
    "mostly_restrictive_answer_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You will answer a question based of the given information below. Try your best to answer the question\n",
    "using the relevant information. But do not make anything up that is not supported, just say \"No sure\"\n",
    "                                                                                                                \n",
    "Question: {question}\n",
    "\n",
    "Relevant Information: {relevant_information} \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple example\n",
    "\n",
    "In this example the the simple and restrictive prompts should result in similar answers, as the provided information is very specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"What is the name of the main character in Harry Potter?\"\n",
    "relevant_text = \"Harry Potter is the main character of the Harry Potter series.\"\n",
    "answer, _ = await answer_question(QUESTION, chat, simple_answer_prompt, relevant_information=relevant_text)\n",
    "print(f\"Answer: {textwrap.fill(answer, 50)}\")\n",
    "answer, _ = await answer_question(QUESTION, chat, restrictive_answer_prompt, relevant_information=relevant_text)\n",
    "print(f\"\\n\\nAnswer: {textwrap.fill(answer, 50)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restrictive vs Simple Prompt\n",
    "\n",
    "Here we should see that the restrictive prompt will not be able to answer the question as no information is provided about the specific question. Whereas, the simple prompt will give an answer, but founded from the models training data and not from the provided information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"What is the name of the main character in Harry Potter?\"\n",
    "irrelevant_text = \"This is a test.\"\n",
    "answer, _ = await answer_question(QUESTION, chat, simple_answer_prompt, relevant_information=irrelevant_text)\n",
    "print(f\"Answer: {textwrap.fill(answer, 50)}\")\n",
    "answer, _ = await answer_question(QUESTION, chat, restrictive_answer_prompt, relevant_information=irrelevant_text)\n",
    "print(f\"\\n\\nAnswer: {textwrap.fill(answer, 50)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example using Restrictive Prompt and Irrelevant or Relevant Information\n",
    "\n",
    "**Question**: Were the house points used much?\n",
    "\n",
    "This question refers to the difference between the books and movies. The movies does not use the house point system that much, but in the books it is different.. More details can be found [here](https://harrypotter.fandom.com/wiki/List_of_differences_between_the_Harry_Potter_books_and_films#1._House_points).\n",
    "\n",
    "**Non-Restrictive Prompt with Irrelevant Information:** \n",
    "The answer, in this case, may not be reliable as it lacks evidence or related context.\n",
    "\n",
    "**Restrictive Prompt with Irrelevant Information:** \n",
    "The system should not attempt to answer the question due to the absence of pertinent data.\n",
    "\n",
    "**Restrictive Prompt with Relevant Information:** \n",
    "The system is expected to answer the question accurately due to the provision of context-specific data from a relevant source.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"Were the house points used much?\"\n",
    "irrelevant_text = \"This is a test.\"\n",
    "print(\"Non restrictive prompt with irrelevant information\")\n",
    "answer, _ = await answer_question(QUESTION, chat, simple_answer_prompt, relevant_information=irrelevant_text)\n",
    "print(f\"Answer: {textwrap.fill(answer, 50)}\")\n",
    "print(\"\\n\\nRestrictive prompt with irrelevant information\")\n",
    "answer, _ = await answer_question(QUESTION, chat, restrictive_answer_prompt, relevant_information=irrelevant_text)\n",
    "print(f\"Answer: {textwrap.fill(answer, 50)}\")\n",
    "print(\"\\n\\nNon restrictive prompt with relevant information\")\n",
    "answer, _ = await answer_question(QUESTION, chat, restrictive_answer_prompt, docsearch=docsearch_recursive, similar_doc_count=12, verbose=True)\n",
    "print(f\"Answer: {textwrap.fill(answer, 50)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All vs Some\n",
    "\n",
    "Here is a cool example of the difference of how you word the question. The first question asks for all whereas, the second question asks for some. The answers are very different. The model should be able to pick up on the fact that it can not reliably give all, but with some relevant information it can definitely give some."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"Can you tell me all the horcruxes from Harry Potter?\"\n",
    "answer, _ = await answer_question(QUESTION, chat, restrictive_answer_prompt, docsearch=docsearch_recursive, similar_doc_count=10)\n",
    "print(f\"Answer: {textwrap.fill(answer, 50)}\")\n",
    "QUESTION = \"Can you tell about some of the horcruxes?\"\n",
    "answer, _ = await answer_question(QUESTION, chat, restrictive_answer_prompt, docsearch=docsearch_recursive, similar_doc_count=10)\n",
    "print(f\"\\n\\nAnswer: {textwrap.fill(answer, 50)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.insider.com/harry-potter-trivia-2016-11#harry-ron-and-hermione-help-save-the-sorcerers-stone-from-being-stolen-how-old-was-its-co-creator-nicholas-flamel-when-he-decided-to-destroy-it-2\n",
    "QUESTIONS = [\n",
    "    \"Many know that Gryffindor's ghost is Nearly Headless Nick. But what is his full name?\",\n",
    "    #  Sir Nicholas de Mimsy-Porpington.\n",
    "    \"Harry, Ron, and Hermione help save the Sorcerer's Stone from being stolen. How old was its co-creator, Nicholas Flamel, when he decided to destroy it?\",\n",
    "    #  665\n",
    "    \"Monkshood and wolfsbane are the same plant, also known as what?\",\n",
    "    #  Aconite\n",
    "    \"How many staircases does Hogwarts have?\",\n",
    "    #  142\n",
    "    \"How many possible Quidditch fouls are there?\",\n",
    "    #  700\n",
    "    \"In The Sorcerer\\’s Stone, Harry and his friends are awarded last-minute House Points, putting Gryffindor ahead of Slytherin by just 10 points. What was the final tally?\",\n",
    "    #  482 to 472\n",
    "    \"Dumbledore has a scar above his left knee that is a perfect map of what?\",\n",
    "    #  The London Underground\n",
    "    \"This one is a two-parter. Where does Vernon Dursley work, and what does the company produce?\",\n",
    "    # Grunnings, a drill manufacturer.\n",
    "    \"For Harry's 17th birthday, what color did Hermione turn the leaves of the Weasley’s crabapple tree?\",\n",
    "    #  Gold\n",
    "    \"Cedric Diggory let Harry use the prefect's bathroom in The Goblet of Fire. What man's statue is next to the special lavatory entrance?\",\n",
    "    #  Boris the Bewildered\n",
    "    \"What is the max speed for a Firebolt broomstick?\",\n",
    "    #  150 mph\n",
    "    \"Harry first took the Knight Bus in The Prisoner of Azkaban. How much does a ticket cost if it includes hot chocolate?\"\n",
    "    #  14 Sickles\n",
    "    \"In the Hall of Prophecy there are rows and rows of glowing orbs. Which row contains the prophecy about Harry and Voldemort?\",\n",
    "    #  97\n",
    "    \"In the Quidditch World Cup, Ireland's team had three main chasers: Mullet, Troy, and Moran. Which one scored the first goal?\",\n",
    "    #  Troy\n",
    "    \"On the wall across from the Room of Requirement, there is a tapestry showing a wizard trying to teach trolls ballet. What's his name?\",\n",
    "    #  Barnabas the Barmy\n",
    "    \"The visitor’s entrance to the Ministry of Magic is an abandoned red telephone booth in London. What is the five-digit code you must dial to get in?\",\n",
    "    #  62442\n",
    "    \"What is the name of the Apparition instructor who comes to Hogwarts in Harry's sixth year?\",\n",
    "    #  Wilkie Twycross\n",
    "    \"Voldemort stole Helga Hufflepuff's cup from an old woman named Hepzibah Smith. What was the name of her house-elf?\",\n",
    "    #  Hokey\n",
    "    \"Ginny Weasley bought a pet Pygmy Puff from her older brothers' joke shop. What did she name it?\",\n",
    "    #  Arnold\n",
    "    \"What is Fred Weasley's chosen code name on Potterwatch, the secretive radio program set up by the Order of the Phoenix?\",\n",
    "    #  Rapier\n",
    "]\n",
    "\n",
    "for question in QUESTIONS:\n",
    "    answer, _ = await answer_question(question, chat, restrictive_answer_prompt, docsearch=docsearch_recursive, similar_doc_count=5)\n",
    "    print(f\"Answer: {textwrap.fill(answer, 50)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of results\n",
    "9 correct, 2 incorrect, 9 unanswered \n",
    "#### Notes\n",
    "However, if you change the prompt, amount of relevant information, and possible temperature, you can get the answers to almost all questions. This means you could possible combine results using bootstrapping or ensemble learning. The ideas of combining results from multiple models increasing the accuracy and reducing the bias. \n",
    "[ensemble learning](https://machinelearningmastery.com/tour-of-ensemble-learning-algorithms/)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"Was Sirius Black a good person?\"\n",
    "\n",
    "answer, _ = await answer_question(QUESTION, chat, restrictive_answer_prompt, docsearch=docsearch_recursive, similar_doc_count=5)\n",
    "print(f\"Answer: {textwrap.fill(answer, 50)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance of Metadata in Document Processing with Generative AI\n",
    "\n",
    "In the era of generative AI models, the significance of metadata in document processing has been further amplified. Metadata encapsulates essential information about data, making it an invaluable asset for maintaining the integrity and transparency of AI operations. \n",
    "\n",
    "## Traceability and Verification\n",
    "\n",
    "Metadata serves as a roadmap, providing crucial details about the source of the information. For generative AI, which is capable of producing large volumes of text, it is vital to keep track of the original sources. The reasons are multifold:\n",
    "\n",
    "1. **Avoiding Misinformation**: Metadata can help ensure the AI model doesn't \"hallucinate,\" or generate information that isn't supported by the input data. By keeping track of the source information, we can verify the generated output against the original context.\n",
    "\n",
    "2. **Double-checking Facts**: For sensitive applications such as scientific research or engineering projects, it's crucial to confirm the accuracy of generated information. Metadata allows users to trace back to the original sources, facilitating the verification process.\n",
    "\n",
    "3. **Citation and Accountability**: Accurate metadata allows for proper citation of the information's source. This not only fulfills academic and professional standards but also promotes accountability and fairness in knowledge sharing.\n",
    "\n",
    "## Metadata: The Silent Workhorse\n",
    "\n",
    "The versatility of metadata allows it to store a wide range of information, from links and page numbers to author names and text sections. However, its significance transcends these particulars. \n",
    "\n",
    "In the vast, interconnected data ecosystems where generative AI operates, metadata functions as the connective tissue, bridging the gap between massive data volumes and precise, reliable outcomes. \n",
    "\n",
    "In summary, the use of metadata is instrumental in preserving the reliability, traceability, and accountability of generative AI systems. By maintaining a clear line of sight to source information, metadata acts as a robust tool for users to verify facts and ensure the integrity of their work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_splitter_by_page(file: io.BytesIO, metadata: dict) -> List[Document]:\n",
    "    '''\n",
    "    Split a PDF file into a list of documents by page\n",
    "    '''\n",
    "    reader = PdfReader(file)\n",
    "    return [\n",
    "        Document(\n",
    "            page_content=page.extract_text(),\n",
    "            metadata={\n",
    "                        **metadata,\n",
    "                        \"page\": page_number, \n",
    "                    },\n",
    "        )\n",
    "        for page_number, page in enumerate(reader.pages)\n",
    "    ]\n",
    "\n",
    "\n",
    "embeddings_path_page = os.getcwd() + \"/embeddings/\" + os.getenv(\"EMBEDDINGS_BY_PAGE_FILE_NAME\") # type: ignore\n",
    "if os.path.exists(embeddings_path_page):\n",
    "    print(\"Embeddings file already exists for page splitter\")\n",
    "    # read embeddings object from file\n",
    "    with open(embeddings_path_page, 'rb') as f:\n",
    "        docsearch_page = pickle.load(f)\n",
    "else:\n",
    "    print(\"Embeddings file does not exist for page splitter\")\n",
    "    # load file into BytesIO object\n",
    "    with open(pdf_path_page, 'rb') as f:\n",
    "        file = io.BytesIO(f.read())\n",
    "    # compute embeddings\n",
    "    docs = doc_splitter_by_page(file, { \"source\": os.getenv(\"PDF_URL\")})\n",
    "    docsearch_page = compute_embeddings(docs, embeddings, embeddings_path_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"can you give me the things that happen to the flying car\"\n",
    "answer, _ = await answer_question(QUESTION, chat, restrictive_answer_prompt, docsearch=docsearch_recursive, similar_doc_count=10)\n",
    "print(f\"Answer: {textwrap.fill(answer, 50)}\")\n",
    "answer, similar_docs = await answer_question(QUESTION, chat, restrictive_answer_prompt, docsearch=docsearch_page, similar_doc_count=10)\n",
    "print(f\"\\nAnswer: {textwrap.fill(answer, 50)}\")\n",
    "\n",
    "print(\"\\nSources:\")\n",
    "for doc in similar_docs:\n",
    "    print(f\"Source: {doc.metadata['source']}\")\n",
    "    print(f\"Page: {doc.metadata['page']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
